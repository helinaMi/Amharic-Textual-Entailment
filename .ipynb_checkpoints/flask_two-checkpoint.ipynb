{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\new\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\new\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\new\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\new\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\new\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\new\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#!/home/selim/DS/python/anaconda3/bin/python\n",
    "from __future__ import print_function\n",
    "\n",
    "from flask import Flask, request, send_from_directory, redirect, render_template, flash, url_for, jsonify, make_response, abort\n",
    "from flask import Flask, render_template\n",
    "from flask_restful import Resource, Api\n",
    "import pickle\n",
    "import numpy as np\n",
    "import sys, os\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "%matplotlib inline\n",
    "from markupsafe import Markup\n",
    "from IPython.display import Image, display\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "from gensim import models\n",
    "import base64\n",
    "\n",
    "import matplotlib.font_manager\n",
    "\n",
    "#for tables in Jupyter\n",
    "from IPython.display import HTML, display\n",
    "#import tabulate\n",
    "import urllib.parse\n",
    "#for visualization\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA as sPCA\n",
    "from sklearn import manifold \n",
    "import os\n",
    "from os.path import join, exists\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "#from pandas.lib import TimeValidator\n",
    "import re\n",
    "import string\n",
    "#import urllib2\n",
    "import json\n",
    "from zipfile import ZipFile\n",
    "from gensim.models import KeyedVectors\n",
    "import sys\n",
    "import codecs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import graphviz\n",
    "#from ggplot import *\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.models import model_from_config, model_from_json\n",
    "\n",
    "from keras.layers import Embedding, Dense, Input, Dropout, Reshape, BatchNormalization, TimeDistributed, Lambda, Layer, merge, LSTM, Bidirectional, Convolution1D, GRU, add, concatenate\n",
    "from keras.callbacks import Callback, ModelCheckpoint, TensorBoard, BaseLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import RMSprop, Adam, SGD, Adagrad\n",
    "import sys \n",
    "from keras.utils import CustomObjectScope\n",
    "\n",
    "from codecs import unicode_escape_encode, unicode_escape_decode, raw_unicode_escape_encode,raw_unicode_escape_decode\n",
    "import logging\n",
    "#sys.setrecursionlimit(2960)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract D:/ect.json\n"
     ]
    }
   ],
   "source": [
    "dataset_filename = 'multinli_0.9'\n",
    "training_sample_size = 1000 # Change this to -1 if you want all\n",
    "train_filename = ('D:/ect.json')\n",
    "if exists(train_filename):\n",
    "    print('Extract %s' % train_filename)\n",
    "    zipfile = open(train_filename, 'r', encoding = 'utf-8-sig') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>በአሽንዳ ባህል ጭፈራ ላይ ብዙ ሴቶች አንድ አይነት ልብስ ለብስው በካሜራ...</td>\n",
       "      <td>አንድ ሰው ከካሜራው ቀጥሎ ነው</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entailment</td>\n",
       "      <td>አንድ ሰው ባቡሩ አቅራቢያ ቆሟል</td>\n",
       "      <td>ሰውየው ውጭ ነው</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>ቁር ያደረገች አንዲት ልጅ ቡናማ ፈረስ እየጋለበች ነው</td>\n",
       "      <td>ልጅቷ እየተጓዘች ነው</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>ጀርባዋ የሚታየው በቀለማት ያሸበረቀች ልብስ የለበሰች አንዲት ሴት ከላይ ...</td>\n",
       "      <td>ሁለት ሴቶች የአካል ብቃት እንቅስቃሴ እያደረጉ ነው</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>አንድ ወጣት የስዕል መጽሐፍ ሲመለከት</td>\n",
       "      <td>አንድ ልጅ ሣር ላይ ቁጭ ብሎ መጽሐፍን ሲመለከት</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            gold                                          sentence1  \\\n",
       "0  contradiction  በአሽንዳ ባህል ጭፈራ ላይ ብዙ ሴቶች አንድ አይነት ልብስ ለብስው በካሜራ...   \n",
       "1     entailment                               አንድ ሰው ባቡሩ አቅራቢያ ቆሟል   \n",
       "2  contradiction                 ቁር ያደረገች አንዲት ልጅ ቡናማ ፈረስ እየጋለበች ነው   \n",
       "3  contradiction  ጀርባዋ የሚታየው በቀለማት ያሸበረቀች ልብስ የለበሰች አንዲት ሴት ከላይ ...   \n",
       "4        neutral                            አንድ ወጣት የስዕል መጽሐፍ ሲመለከት   \n",
       "\n",
       "                          sentence2  \n",
       "0               አንድ ሰው ከካሜራው ቀጥሎ ነው  \n",
       "1                        ሰውየው ውጭ ነው  \n",
       "2                     ልጅቷ እየተጓዘች ነው  \n",
       "3  ሁለት ሴቶች የአካል ብቃት እንቅስቃሴ እያደረጉ ነው  \n",
       "4    አንድ ልጅ ሣር ላይ ቁጭ ብሎ መጽሐፍን ሲመለከት  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import codecs\n",
    "import io\n",
    "from json import loads\n",
    "\n",
    "def loadDataset(filename, size=-1):\n",
    "    label_category = {\n",
    "        'neutral': 0,\n",
    "        'entailment': 1,\n",
    "        'contradiction': 2\n",
    "    }\n",
    "    dataset = []\n",
    "    sentence1 = []\n",
    "    sentence2 = []\n",
    "    labels = []\n",
    "    with codecs.open(filename, 'r',  'utf-8-sig') as f:\n",
    "        if len(f.readlines(f)) != 0:\n",
    "            f.seek(0)\n",
    "            i = 0\n",
    "         \n",
    "            for line in f:\n",
    "                row = json.loads(str(line).encode())\n",
    "                if size == -1 or i < size:\n",
    "                    dataset.append(row)\n",
    "                    label = row[\"gold\"]\n",
    "                    if label in label_category:\n",
    "                        sentence1.append( row[\"sentence1\"])\n",
    "                        sentence2.append( row[\"sentence2\"])\n",
    "\n",
    "                        labels.append( label_category[label] )\n",
    "                   \n",
    "                \n",
    "        return (dataset, sentence1, sentence2, labels)\n",
    "\n",
    "\n",
    "(train_dataset, train_sentence1, train_sentence2, train_labels) = loadDataset(train_filename, training_sample_size)\n",
    "\n",
    "train_df = pd.DataFrame(train_dataset)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "803\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_features = train_df[['sentence1', 'sentence2', 'gold']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_FOLDER = os.path.join('static', 'img_pool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v= None\n",
    "sw = None\n",
    "graph =None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathft = 'E:/ftl.txt'\n",
    "pathwv = 'E:/wvl.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "app.secret_key = b'_5#y2L\"F4Q8z\\n\\xec]/'\n",
    "app.config['UPLOAD_FOLDER'] = IMAGE_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ma():\n",
    "    global w2v,sw\n",
    "    sw = KeyedVectors.load_word2vec_format(pathft)\n",
    "    w2v = KeyedVectors.load_word2vec_format(pathwv)\n",
    "\n",
    "    graph  = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = ma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run model_load.ipynb\n",
    "__name__ == '__main__' and '__file__' not in globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hp\\Anaconda3\\envs\\new\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1242: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\hp\\Anaconda3\\envs\\new\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1344: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ft = ft()\n",
    "wv = wv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    ft\n",
    "    wv\n",
    "    load\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:File `'each_plt.ipynb.py'` not found.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run each_plt.ipynb\n",
    "__name__ == '__main__' and '__file__' not in globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/disimilarwv')\n",
    "def dis():\n",
    "    return render_template('dissimilar.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/morphemewv')\n",
    "def morp():\n",
    "    return render_template('morp.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/simwv')\n",
    "def simi():\n",
    "    return render_template('similar.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/analogyw')\n",
    "def ana():\n",
    "    return render_template('analogy.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/morphemew')\n",
    "def swsim():\n",
    "    return render_template('swsim.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/simwv', methods = [\"POST\", \"GET\"])\n",
    "\n",
    "def simwv():\n",
    "    if request.method=='POST':\n",
    "        if 'sentences' not in request.form :\n",
    "            flash('No word post')\n",
    "            redirect(request.url)\n",
    "        elif request.form['sentences'] == '':\n",
    "            flash('No word')\n",
    "            redirect(request.url)\n",
    "        else:\n",
    "            texta = request.form.get('sentences')\n",
    "            try:\n",
    "                results = w2v.most_similar(texta.split())\n",
    "            except:\n",
    "                results = ''\n",
    "            logging.info(\"dissimilar for %s: %s\" % (texta, results))\n",
    "\n",
    "    return render_template('similar.html', sentences=texta,results=results) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/simft', methods = [\"POST\", \"GET\"])\n",
    "\n",
    "def simft():\n",
    "    if request.method=='POST':\n",
    "        if 'sentence' not in request.form :\n",
    "            flash('No word post')\n",
    "            redirect(request.url)\n",
    "        elif request.form['sentence'] == '':\n",
    "            flash('No word')\n",
    "            redirect(request.url)\n",
    "        else:\n",
    "            texta = request.form.get('sentence')\n",
    "            try:\n",
    "        \n",
    "\n",
    "                results = sw.most_similar(texta.split())\n",
    "            except:\n",
    "                results=[]\n",
    "                results.append((results))\n",
    "                results=','.join(str(string) for string in results)\n",
    "                #new_list = codecs.decode(new_list, \"unicode_escape\",errors=\"replace\")\n",
    "                results = '<br>'.join(str(string) for string in results)\n",
    "\n",
    "\n",
    "    return render_template('similar.html', sentence=texta,result=results) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/disimilarwv', methods = [\"POST\", \"GET\"])\n",
    "\n",
    "def disimilarwv():\n",
    "    if request.method=='POST':\n",
    "        if 'sentence' not in request.form :\n",
    "            flash('Post at least three words')\n",
    "            redirect(request.url)\n",
    "        elif request.form['sentence'] == '':\n",
    "            flash('No words')\n",
    "            redirect(request.url)\n",
    "        else:\n",
    "            texta = request.form.get('sentence')\n",
    "            try:\n",
    "                resultd = w2v.wv.doesnt_match(texta.split())\n",
    "            except:\n",
    "                resultd = ''\n",
    "            logging.info(\"dissimilar for %s: %s\" % (texta, resultd))\n",
    "            y= (\"dissimilar for %s: %s\" % (texta, resultd))\n",
    "          \n",
    "    return render_template('dissimilar.html', y= y, sentence=texta, result=resultd) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/disimilarft', methods = [\"POST\", \"GET\"])\n",
    "\n",
    "def disimilarft():\n",
    "    if request.method=='POST':\n",
    "        if 'sentenced' not in request.form :\n",
    "            flash('Post at least three words')\n",
    "            redirect(request.url)\n",
    "        elif request.form['sentenced'] == '':\n",
    "            flash('No words')\n",
    "            redirect(request.url)\n",
    "        else:\n",
    "            texta = request.form.get('sentenced')\n",
    "            try:\n",
    "                resultd = sw.wv.doesnt_match(texta.split())\n",
    "            except:\n",
    "                resultd = ''\n",
    "            logging.info(\"dissimilar for %s: %s\" % (texta, resultd))\n",
    "            x= (\"The most dissimilar for query %s: is  %s\" % (texta, resultd))\n",
    "          \n",
    "    return render_template('dissimilar.html',x=x ,sentenced=texta, resultd=resultd) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/morphemewv', methods = [\"POST\", \"GET\"])\n",
    "\n",
    "def morphemewv():\n",
    "    if request.method=='POST':\n",
    "        if 'sentencew' not in request.form :\n",
    "            flash('No sentence post')\n",
    "            redirect(request.url)\n",
    "        elif request.form['sentencew'] == '':\n",
    "            flash('No sentence')\n",
    "            redirect(request.url)\n",
    "        else:\n",
    "            texta = request.form.get('sentencew')\n",
    "            try:\n",
    "                resultw =  {search_term:[item[0] for item in w2v.wv.most_similar(texta.split(), topn=6)]\n",
    "                        for search_term in texta.split()}\n",
    "            except:\n",
    "                resultw = []\n",
    "            logging.info(\"MorphemsWV for %s: %s\" % (texta, resultw))\n",
    "       \n",
    "         \n",
    "    return render_template('morp.html', sentencew=texta, result=resultw) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/morphemeft', methods = [\"POST\", \"GET\"])\n",
    "\n",
    "def morphemft():\n",
    "    if request.method=='POST':\n",
    "        if 'sentencef' not in request.form :\n",
    "            flash('No sentence post')\n",
    "            redirect(request.url)\n",
    "        elif request.form['sentencef'] == '':\n",
    "            flash('No sentence')\n",
    "            redirect(request.url)\n",
    "        else:\n",
    "            texta = request.form.get('sentencef')\n",
    "            try:\n",
    "                resultf =  {search_term:[item[0] for item in sw.wv.most_similar(texta.split(), topn=6)]\n",
    "                        for search_term in texta.split()}\n",
    "            except:\n",
    "                resultf = []\n",
    "            logging.info(\"MorphemsSW for %s: %s\" % (texta, resultf))\n",
    "       \n",
    "         \n",
    "    return render_template('morp.html', sentencef=texta, resultf=resultf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/morphemew', methods = [\"POST\", \"GET\"])\n",
    "\n",
    "def morphemew():\n",
    "    if request.method=='POST':\n",
    "        if 'sentencew' not in request.form :\n",
    "            flash('No sentence post')\n",
    "            redirect(request.url)\n",
    "        elif request.form['sentencew'] == '':\n",
    "            flash('No sentence')\n",
    "            redirect(request.url)\n",
    "        else:\n",
    "            texta = request.form.get('sentencew')\n",
    "            textb = request.form.get('sentencey')\n",
    "            try:\n",
    "                resultt = w2v.similarity(texta,textb)\n",
    "            except:\n",
    "                resultt=''\n",
    "      \n",
    "\n",
    "            logging.info(\"Similarity score  for %s %s: %s\" % (texta,textb,  resultt))\n",
    "            y= (\"'%s' and '%s' is %s\" %  (texta,textb,  result))\n",
    "\n",
    "        \n",
    "\n",
    "         \n",
    "    return render_template('swsim.html',y=y, sentencew=texta,sentencey=textb, result=resultt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/morphemes', methods = [\"POST\", \"GET\"])\n",
    "\n",
    "def morphemes():\n",
    "    if request.method=='POST':\n",
    "        if 'sentences' not in request.form :\n",
    "            flash('No sentence post')\n",
    "            redirect(request.url)\n",
    "        elif request.form['sentences'] == '':\n",
    "            flash('No sentence')\n",
    "            redirect(request.url)\n",
    "        else:\n",
    "            texti = request.form.get('sentences')\n",
    "            textj = request.form.get('sentencei')\n",
    "            try:\n",
    "                result = sw.similarity(texti,textj)\n",
    "            except:\n",
    "                result=''\n",
    "      \n",
    "\n",
    "            logging.info(\"Similarity score  for %s %s: %s\" % (texti,textj,  result))\n",
    "            x= (\"'%s' and '%s' is %s\" %  (texti,texti,  result))\n",
    "\n",
    "\n",
    "         \n",
    "    return render_template('swsim.html', x=x, sentences=texti,sentencei=textj, res=result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/analogyw', methods = [\"POST\", \"GET\"])\n",
    "\n",
    "def analogyw():\n",
    "    if request.method=='POST':\n",
    "        if 'sentencev' not in request.form :\n",
    "            flash('No sentence post')\n",
    "            redirect(request.url)\n",
    "        elif request.form['sentencev'] == '':\n",
    "            flash('No sentence')\n",
    "            redirect(request.url)\n",
    "        else:\n",
    "            texta = request.form['sentencev']\n",
    "            texta = [texta] if type(texta) == np.str else texta\n",
    "            for example in texta:\n",
    "                    a, b, x = example.split()\n",
    "            try:\n",
    "                \n",
    "        \n",
    "                    predicted = w2v.most_similar([x, b], [a],topn=3)\n",
    "                \n",
    "            except:\n",
    "                predicted=[]\n",
    "            logging.info (\"'%s' is to '%s' as '%s' is to '%s'\" % (a, b, x, predicted))\n",
    "            y = (\"if '%s' is to '%s' as '%s' is to '%s'\" % (a, b, x, predicted))\n",
    "\n",
    "\n",
    "         \n",
    "       \n",
    "         \n",
    "    return render_template('analogy.html',y=y, sentencev=texta, res= predicted) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/analogys', methods = [\"POST\", \"GET\"])\n",
    "\n",
    "def analogys():\n",
    "    if request.method=='POST':\n",
    "        if 'sentences' not in request.form :\n",
    "            flash('No sentence post')\n",
    "            redirect(request.url)\n",
    "        elif request.form['sentences'] == '':\n",
    "            flash('No sentence')\n",
    "            redirect(request.url)\n",
    "        else:\n",
    "            texta = request.form['sentences']\n",
    "            texta = [texta] if type(texta) == np.str else texta\n",
    "            for example in texta:\n",
    "                    a, b, x = example.split()\n",
    "            try:\n",
    "                \n",
    "        \n",
    "                    predicted = sw.most_similar([x, b], [a],topn=3)\n",
    "                \n",
    "            except:\n",
    "                predicted=[]\n",
    "            logging.info (\"'%s' is to '%s' as '%s' is to '%s'\" % (a, b, x, predicted))\n",
    "            x = (\"if '%s' is to '%s' as '%s' is to '%s'\" % (a, b, x, predicted))\n",
    "\n",
    "\n",
    "         \n",
    "       \n",
    "         \n",
    "    return render_template('analogy.html',x =x, sentences=texta, result= predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/compare_models', methods = [\"POST\", \"GET\"])\n",
    "def Dmain():\n",
    "\n",
    "    model_dir_path = 'D:\\models'\n",
    "    models = ['WBWA','MPCM','BiMPM','RSSM']\n",
    "    acc_cmp = dict()\n",
    "    val_acc_cmp = dict()\n",
    "    labels = list()\n",
    "    for model_name in models:\n",
    "        acc_cmp[model_name] = list()\n",
    "        val_acc_cmp[model_name] = list()\n",
    "        history_file_name = model_name + '-history.npy'\n",
    "        history_file_path = os.path.join(model_dir_path, history_file_name)\n",
    "        history = np.load(history_file_path,allow_pickle=True).item()\n",
    "        labels_not_set = len(labels) == 0\n",
    "        for index in range(0, 20, 2):\n",
    "            acc_data = history['acc']\n",
    "            val_acc_data = history['val_acc']\n",
    "            epoch = min(len(acc_data)-1, index)\n",
    "            acc = acc_data[epoch]\n",
    "            val_acc = val_acc_data[epoch]\n",
    "            acc_cmp[model_name].append(acc)\n",
    "            val_acc_cmp[model_name].append(val_acc)\n",
    "            if labels_not_set:\n",
    "                labels.append(epoch)\n",
    "    plt.style.use('ggplot')\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    ax= plt.subplot2grid((2, 1), (0, 0))\n",
    "    ax.set_title('Training Accuracy')\n",
    "    for model_name, acc_data in acc_cmp.items():\n",
    "        ax.plot(labels, acc_data, label=model_name)\n",
    "    ax.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    img = io.BytesIO() \n",
    "    plt.savefig(img, format='png')\n",
    "    img.seek(0)\n",
    "\n",
    "    plot_Accuracy = urllib.parse.quote(base64.b64encode(img.read()).decode())\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "\n",
    "    ax1=plt.subplot2grid((2, 1), (0, 0))\n",
    "    ax1.set_title('Validation Accuracy')\n",
    "    for model_name, acc_data in val_acc_cmp.items():\n",
    "        ax1.plot(labels, acc_data, label=model_name)\n",
    "    ax1.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    img = io.BytesIO() \n",
    "    plt.savefig(img, format='png')\n",
    "    img.seek(0)\n",
    "\n",
    "    plot_url = urllib.parse.quote(base64.b64encode(img.read()).decode())\n",
    "  \n",
    "    return render_template('compare_models.html', plot_url=plot_url, plot_Accuracy=plot_Accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA for word vectors \n",
    "@app.route('/plot_url', methods = [\"POST\", \"GET\"])\n",
    "\n",
    "\n",
    "def show_closest_line():\n",
    "    if request.method=='POST':\n",
    "        if 'sentence' not in request.form :\n",
    "            flash('No sentence post')\n",
    "            redirect(request.url)\n",
    "        elif request.form['sentence'] == '':\n",
    "            flash('No sentence')\n",
    "            redirect(request.url)\n",
    "        else:\n",
    "            font = matplotlib.font_manager.FontProperties(fname='C:/Users/hp/Anaconda3/envs/tfp3.6/Library/fonts/abyssinica_sil.ttf')\n",
    "            FONT_SIZE = 20\n",
    "            TEXT_KW = dict(fontsize=FONT_SIZE, fontweight='bold', fontproperties=font)\n",
    "\n",
    "            texta = request.form.get('sentence')\n",
    "\n",
    "            n=10\n",
    "            tops = w2v.similar_by_word(texta, topn=n, restrict_vocab=None)\n",
    "\n",
    "            \n",
    "            items = [texta] + [x[0] for x in tops]\n",
    "\n",
    "            wvecs = np.array([w2v.word_vec(wd, use_norm=True) for wd in items])\n",
    "\n",
    "\n",
    "\n",
    "            tsne = manifold.TSNE(n_components=2, init='pca')\n",
    "            coords = tsne.fit_transform(wvecs)\n",
    "            #print(\"kl-divergence: %0.8f\" % tsne.kl_divergence_)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            plt.figure(num=None, figsize=(8, 8), dpi=80, facecolor='w', edgecolor='k')\n",
    "            plt.tick_params(\n",
    "                axis='both',          \n",
    "                which='both',      \n",
    "                bottom=False,      \n",
    "                left=False,         \n",
    "                labelbottom=False,\n",
    "                labelleft=False)\n",
    "\n",
    "            lim = max([abs(x) for x in coords[:,0] + coords[:,1]])\n",
    "            plt.xlim([-lim,lim])\n",
    "            plt.ylim([-lim,lim])\n",
    "            plt.scatter(coords[2:,0], coords[2:,1])\n",
    "            plt.scatter(coords[0:1,0], coords[0:1,1], color='black')\n",
    "            plt.scatter(coords[1:2,0], coords[1:2,1], color='orange')\n",
    "\n",
    "            for item, x, y in zip(items[2:], coords[2:,0], coords[2:,1]):\n",
    "                plt.annotate( item, xy=(x, y), xytext=(-2, 2), textcoords='offset points', \n",
    "                             ha='right', va='bottom', color='purple', **TEXT_KW)\n",
    "\n",
    "            x0=coords[0,0]\n",
    "            y0=coords[0,1]\n",
    "            plt.annotate( texta , xy=(x0, y0), xytext=(-2, 2), textcoords='offset points', \n",
    "                         ha='right', va='bottom', color='black',**TEXT_KW)\n",
    "\n",
    "            x1=coords[1,0]\n",
    "            y1=coords[1,1] \n",
    "            plt.annotate( items[1] , xy=(x1, y1), xytext=(-2, 2), textcoords='offset points', \n",
    "                         ha='right', va='bottom', color='orange', **TEXT_KW )\n",
    "\n",
    "            ax = plt.gca()\n",
    "\n",
    "            r = math.sqrt( (x1-x0)**2 + (y1-y0)**2 )\n",
    "\n",
    "            circle = plt.Circle((x0, y0), r, color='orange', fill=False)\n",
    "            ax.add_artist(circle)\n",
    "\n",
    "           \n",
    "\n",
    "\n",
    "            img = io.BytesIO() \n",
    "            plt.savefig(img, format='png')\n",
    "            img.seek(0)\n",
    "\n",
    "            plot_url = urllib.parse.quote(base64.b64encode(img.read()).decode())\n",
    "\n",
    "          \n",
    "            return render_template('plot_url.html',sentence=texta, plot_url=plot_url)\n",
    " \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/', methods = [\"POST\", \"GET\"])\n",
    "def index():\n",
    "    lossf = historyf['loss'][4]\n",
    "    accuracyf = historyf['acc'][4]\n",
    "    lossw = historyv['loss'][4]\n",
    "    accuracyw = historyv['acc'][4]\n",
    "  \n",
    "   \n",
    "\n",
    "\n",
    "   \n",
    "        \n",
    "    return render_template('indexx.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/layout', methods = [\"POST\", \"GET\"])\n",
    "def home():\n",
    "    return render_template('layout.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/grid', methods =[\"POST\", \"GET\"])\n",
    "def grid():\n",
    "\n",
    "   \n",
    "\n",
    "    pltal = plotallv\n",
    "    accuracyw = historyv['acc'][4]\n",
    "\n",
    "    return render_template('grid.html',pltal=pltal,accuracyw=accuracyw )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/grida', methods =[\"POST\", \"GET\"])\n",
    "\n",
    "def grida():\n",
    "\n",
    "    pltalf=plotallf\n",
    "    accuracyf = historyf['acc'][4]\n",
    "\n",
    "\n",
    "    return render_template('grida.html', pltalf=pltalf,accuracyf=accuracyf)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/plot')\n",
    "def plot():\n",
    "    img_filename = os.path.join(app.config['UPLOAD_FOLDER'], 'training-history-comparison.png')\n",
    "    return render_template('plot.html', img_filename=img_filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datapoint(texta, textb):\n",
    "    texta = [texta] if type(texta) == np.str else texta\n",
    "    textb = [textb] if type(textb) == np.str else textb\n",
    "\n",
    "    tokenizer = configf['tokenizer']['tokenizer']\n",
    "    texta = tokenizer.texts_to_sequences(texta)\n",
    "    textb = tokenizer.texts_to_sequences(textb)\n",
    "\n",
    "    texta = pad_sequences(texta, maxlen = configf['tokenizer']['max_seq_length'])\n",
    "    textb = pad_sequences(textb, maxlen = configf['tokenizer']['max_seq_length'])\n",
    "    return(texta,textb)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_entft(texta, textb):\n",
    "    ret = dict()\n",
    "    texta, textb = prepare_datapoint(texta,textb)\n",
    "    with graphf.as_default():\n",
    "            ent_class = modelf.predict([texta,textb], batch_size=1,verbose = 0)[0]\n",
    "    argmax_ent = np.argmax(ent_class)\n",
    "    entel_class_txt  = ([\"Neutral\", \"Postive\", \"Negative\"][np.argmax(ent_class)]+\" entailment\" )\n",
    "    ent_score = ent_class[argmax_ent]\n",
    "    return(entel_class_txt, ent_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_entwv(texta, textb):\n",
    "    ret = dict()\n",
    "    texta, textb = prepare_datapoint(texta,textb)\n",
    "    with graphv.as_default():\n",
    "            ent_class = modelv.predict([texta,textb], batch_size=1,verbose = 0)[0]\n",
    "    argmax_ent = np.argmax(ent_class)\n",
    "    entel_class_txt  = ([\"Neutral\", \"Postive\", \"Negative\"][np.argmax(ent_class)]+\" entailment\" )\n",
    "    ent_score = ent_class[argmax_ent]\n",
    "    return(entel_class_txt, ent_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/ft', methods = [\"POST\", \"GET\"])\n",
    "\n",
    "def ft():\n",
    "    \n",
    "    if request.method=='POST':\n",
    "        if not request.form[\"sentencea\"]:\n",
    "            flash('No Premises post')\n",
    "            redirect(request.url)\n",
    "        elif not request.form[\"sentenceb\"]:\n",
    "            flash('No Hypotesis')\n",
    "            redirect(request.url)\n",
    "        elif request.form['sentencea'] == '' and  request.form['sentenceb'] == '':\n",
    "            flash('Please Enter the two Sentences')\n",
    "            redirect(request.url)\n",
    "\n",
    "        else:\n",
    "\n",
    "            textc = request.form['sentencea']\n",
    "            textd = request.form['sentenceb']\n",
    "            pred, score = predict_entft(textc, textd)\n",
    "            \n",
    "\n",
    "            return render_template(\"entailment_classification_result.html\", sentencea=textc, pred= pred, score= score, sentenceb=textd)\n",
    "    return render_template('ec.html' ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@app.route('/true')\n",
    "\n",
    "def true():\n",
    "   \n",
    "    sone=[]\n",
    "    sonemis=[]\n",
    "\n",
    "    new_list =[]\n",
    "    new_listmis =[]\n",
    "\n",
    "    counts=0\n",
    "    countf=0\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "    for (i) in range(16):\n",
    "        \n",
    "        trains1, trains2, label = train_df_features.iloc[i]\n",
    "        sentence = trains1\n",
    "        sentencea = trains2\n",
    "       \n",
    "\n",
    "        trains1, trains2 =prepare_datapoint(trains1,trains2)\n",
    "      \n",
    "        \n",
    "        with graphf.as_default(): \n",
    "            pridiction = modelf.predict([trains1, trains2])[0]\n",
    "        x =np.argmax(pridiction)\n",
    "        r= ([\"neutral\", \"entailment\", \"contradiction\"][np.argmax(pridiction)])\n",
    "   \n",
    "       \n",
    "      \n",
    "     \n",
    "        \n",
    "        if label==r:\n",
    "            sone.append('sentence1: ' +  (sentence))\n",
    "            sone.append('sentence2:  '+  (sentencea))\n",
    "            sone.append('actual_label: '+(label))\n",
    "            sone.append('pridicted_label: '+ r)\n",
    "            counts+=1\n",
    "        if label!=r:\n",
    "            sonemis.append('sentence1: ' +  (sentence))\n",
    "            sonemis.append('sentence2:  '+  (sentencea))\n",
    "            sonemis.append('actual_label: '+(label))\n",
    "            sonemis.append('pridicted_label: '+ r)\n",
    "            countf+=1\n",
    "                \n",
    "        #new_list.append= [str(sone).split(maxsplit=0)]\n",
    "        #print(len(sone))\n",
    "\n",
    "        #new_list=[re.sub(',/n ', ' ', s.strip()) for s in sone]\n",
    "        #new_list='[' + ' '(i for item in sone)+ ']'\n",
    "        #new_list.append([string.replace((\"\"\",\"\"\"), \"\"\" \"\"\") for string in sone])\n",
    "        new_list=','.join(str(string) for string in sone)\n",
    "        #new_list = codecs.decode(new_list, \"unicode_escape\",errors=\"replace\")\n",
    "        new_list = '<br>'.join(str(string) for string in sone)\n",
    "        new_listmis=','.join(str(string) for string in sonemis)\n",
    "        #new_list = codecs.decode(new_list, \"unicode_escape\",errors=\"replace\")\n",
    "        new_listmis = '<br>'.join(str(string) for string in sonemis)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        #t =(train_df_features.iloc[i][0])\n",
    "        #train_df.append(pd.DataFrame.iloc[i])\n",
    "        #sum=0\n",
    "        #e = sum([i for z in label[i] if z==r[i]])\n",
    "\n",
    "            \n",
    "            \n",
    "       \n",
    "            \n",
    "        \n",
    "     \n",
    "\n",
    "\n",
    "\n",
    "    #print(new_list)\n",
    "    #print(new_listmis)\n",
    "\n",
    "    #print(sone)\n",
    "    #print(sonemis)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return render_template('label.html',d=new_list, m= new_listmis ,e=counts, n=countf) \n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "@app.route('/truewv')\n",
    "\n",
    "def test():\n",
    "   \n",
    "   \n",
    "    sone=[]\n",
    "    sonemis=[]\n",
    "\n",
    "    new_list =[]\n",
    "    new_listmis =[]\n",
    "\n",
    "    counts=0\n",
    "    countf=0\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "    for (i) in range(16):\n",
    "        \n",
    "        trains1, trains2, label = train_df_features.iloc[i]\n",
    "        sentence = trains1\n",
    "        sentencea = trains2\n",
    "       \n",
    "\n",
    "        trains1, trains2 =prepare_datapoint(trains1,trains2)\n",
    "      \n",
    "        \n",
    "        with graphv.as_default(): \n",
    "            pridiction = modelv.predict([trains1, trains2])[0]\n",
    "        x =np.argmax(pridiction)\n",
    "        r= ([\"neutral\", \"entailment\", \"contradiction\"][np.argmax(pridiction)])\n",
    "   \n",
    "       \n",
    "      \n",
    "     \n",
    "        \n",
    "        if label==r:\n",
    "            sone.append('sentence1: ' +  (sentence))\n",
    "            sone.append('sentence2:  '+  (sentencea))\n",
    "            sone.append('actual_label: '+(label))\n",
    "            sone.append('pridicted_label: '+ r)\n",
    "            counts+=1\n",
    "        if label!=r:\n",
    "            sonemis.append('sentence1: ' +  (sentence))\n",
    "            sonemis.append('sentence2:  '+  (sentencea))\n",
    "            sonemis.append('actual_label: '+(label))\n",
    "            sonemis.append('pridicted_label: '+ r)\n",
    "            countf+=1\n",
    "                \n",
    "        #new_list.append= [str(sone).split(maxsplit=0)]\n",
    "        #print(len(sone))\n",
    "\n",
    "        #new_list=[re.sub(',/n ', ' ', s.strip()) for s in sone]\n",
    "        #new_list='[' + ' '(i for item in sone)+ ']'\n",
    "        #new_list.append([string.replace((\"\"\",\"\"\"), \"\"\" \"\"\") for string in sone])\n",
    "        new_list=','.join(str(string) for string in sone)\n",
    "        #new_list = codecs.decode(new_list, \"unicode_escape\",errors=\"replace\")\n",
    "        new_list = '<br>'.join(str(string) for string in sone)\n",
    "        new_listmis=','.join(str(string) for string in sonemis)\n",
    "        #new_list = codecs.decode(new_list, \"unicode_escape\",errors=\"replace\")\n",
    "        new_listmis = '<br>'.join(str(string) for string in sonemis)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        #t =(train_df_features.iloc[i][0])\n",
    "        #train_df.append(pd.DataFrame.iloc[i])\n",
    "        #sum=0\n",
    "        #e = sum([i for z in label[i] if z==r[i]])\n",
    "\n",
    "            \n",
    "            \n",
    "       \n",
    "            \n",
    "        \n",
    "     \n",
    "\n",
    "\n",
    "\n",
    "    #print(new_list)\n",
    "    #print(new_listmis)\n",
    "\n",
    "    #print(sone)\n",
    "    #print(sonemis)\n",
    "\n",
    "\n",
    "\n",
    "    return render_template('test.html',d=new_list, m= new_listmis, e=counts, n=countf) \n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/wv', methods = [\"POST\", \"GET\"])\n",
    "\n",
    "def wv():\n",
    "   \n",
    "    if request.method=='POST':\n",
    "        if 'sentencea' not in request.form or 'sentenceb' not in request.form:\n",
    "            flash('No sentence post')\n",
    "            redirect(request.url)\n",
    "        elif request.form['sentencea'] == '' or  request.form['sentenceb'] == '':\n",
    "            flash('No sentence')\n",
    "            redirect(request.url)\n",
    "        else:\n",
    "\n",
    "            textc = request.form['sentencea']\n",
    "            textd = request.form['sentenceb']\n",
    "            pred, score = predict_entwv(textc, textd)\n",
    "           \n",
    "            return render_template(\"entailment_classification_result.html\", sentencea=textc, pred= pred, score= score, sentenceb=textd)\n",
    "    return render_template('ec.html') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug: * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:16:57] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:17:05] \"\u001b[37mGET /morphemew HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:17:05] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:17:10] \"\u001b[37mGET /morphemewv HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:17:10] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:17:14] \"\u001b[37mGET /simwv HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:17:14] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:17:22] \"\u001b[37mPOST /simft HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:17:22] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:17:40] \"\u001b[37mPOST /simwv HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:17:40] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:17:46] \"\u001b[37mGET /disimilarwv HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:17:46] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\new\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n",
      "C:\\Users\\hp\\Anaconda3\\envs\\new\\lib\\site-packages\\gensim\\models\\keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:17:49] \"\u001b[37mPOST /disimilarwv HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:17:49] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:17:53] \"\u001b[37mPOST /disimilarft HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:17:53] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:18:03] \"\u001b[37mPOST /disimilarwv HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:18:03] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:18:19] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:18:25] \"\u001b[37mGET /morphemew HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:18:25] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:18:31] \"\u001b[37mGET /disimilarwv HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:18:31] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:18:35] \"\u001b[37mPOST /disimilarwv HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:18:35] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:18:43] \"\u001b[37mPOST /disimilarft HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:18:43] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:18:58] \"\u001b[37mPOST /disimilarft HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:18:58] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:19:17] \"\u001b[37mPOST /disimilarwv HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:19:17] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:19:25] \"\u001b[37mPOST /disimilarft HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:19:25] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:19:58] \"\u001b[37mPOST /disimilarwv HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:19:58] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:20:17] \"\u001b[37mPOST /disimilarft HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:20:17] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:20:59] \"\u001b[37mGET /simwv HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:20:59] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:21:04] \"\u001b[37mPOST /simft HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:21:04] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:21:35] \"\u001b[37mGET /morphemewv HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:21:35] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\new\\lib\\site-packages\\ipykernel_launcher.py:15: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  from ipykernel import kernelapp as app\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:21:38] \"\u001b[37mPOST /morphemeft HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:21:38] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:22:26] \"\u001b[37mGET /disimilarwv HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:22:26] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:22:33] \"\u001b[37mPOST /disimilarwv HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:22:33] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:22:58] \"\u001b[37mPOST /disimilarft HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:22:58] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:23:28] \"\u001b[37mPOST /disimilarwv HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:23:28] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:25:35] \"\u001b[37mGET /simwv HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:25:35] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:29:31] \"\u001b[37mGET /morphemew HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:29:31] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:29:40] \"\u001b[37mGET /analogyw HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:29:40] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:29:53] \"\u001b[37mPOST /analogys HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:29:53] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:30:04] \"\u001b[37mPOST /analogyw HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:30:04] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:30:16] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:30:29] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:30:32] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:30:34] \"\u001b[37mGET /morphemew HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:30:34] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:30:38] \"\u001b[37mGET /morphemewv HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:30:38] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:31:38] \"\u001b[37mGET /analogyw HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:31:38] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:32:49] \"\u001b[37mGET /morphemewv HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:32:49] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:33:36] \"\u001b[37mGET /analogyw HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:33:36] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:33:38] \"\u001b[37mGET /morphemew HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:33:38] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "ERROR:__main__:Exception on /morphemew [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\new\\lib\\site-packages\\flask\\app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\new\\lib\\site-packages\\flask\\app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\new\\lib\\site-packages\\flask\\app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\new\\lib\\site-packages\\flask\\_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\new\\lib\\site-packages\\flask\\app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\new\\lib\\site-packages\\flask\\app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"<ipython-input-27-ee84195215ef>\", line 21, in morphemew\n",
      "    y= (\"'%s' and '%s' is %s\" %  (wt1,wt2,  result))\n",
      "NameError: name 'wt1' is not defined\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:33:43] \"\u001b[1m\u001b[35mPOST /morphemew HTTP/1.1\u001b[0m\" 500 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:33:46] \"\u001b[37mGET /morphemew HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:33:46] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "ERROR:__main__:Exception on /morphemes [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\new\\lib\\site-packages\\flask\\app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\new\\lib\\site-packages\\flask\\app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\new\\lib\\site-packages\\flask\\app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\new\\lib\\site-packages\\flask\\_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\new\\lib\\site-packages\\flask\\app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\hp\\Anaconda3\\envs\\new\\lib\\site-packages\\flask\\app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"<ipython-input-28-72f7aef2be50>\", line 21, in morphemes\n",
      "    x= (\"'%s' and '%s' is %s\" %  (wt1,wt2,  result))\n",
      "NameError: name 'wt1' is not defined\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:33:49] \"\u001b[1m\u001b[35mPOST /morphemes HTTP/1.1\u001b[0m\" 500 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:34:01] \"\u001b[37mGET /morphemew HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:34:01] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:34:04] \"\u001b[37mGET /simwv HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:34:04] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:34:08] \"\u001b[37mPOST /simft HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [27/Sep/2020 18:34:08] \"\u001b[33mGET /static/vendor/owl.carousel/static/owl.carousel.min.css HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "\n",
    "    app.run()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
