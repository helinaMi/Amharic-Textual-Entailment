{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\new\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\new\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\new\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\new\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\new\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\new\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#!/home/selim/DS/python/anaconda3/bin/python\n",
    "\n",
    "from flask import Flask, request, send_from_directory, redirect, render_template, flash, url_for, jsonify, make_response, abort\n",
    "from flask import Flask, render_template\n",
    "from flask_restful import Resource, Api\n",
    "import pickle\n",
    "import numpy as np\n",
    "import sys, os\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "%matplotlib inline\n",
    "\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from os.path import join, exists\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "#from pandas.lib import TimeValidator\n",
    "\n",
    "#import urllib2\n",
    "import json\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import graphviz\n",
    "#from ggplot import *\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.models import model_from_config, model_from_json\n",
    "\n",
    "from keras.layers import Embedding, Dense, Input, Dropout, Reshape, BatchNormalization, TimeDistributed, Lambda, Layer, merge, LSTM, Bidirectional, Convolution1D, GRU, add, concatenate\n",
    "from keras.callbacks import Callback, ModelCheckpoint, TensorBoard, BaseLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import RMSprop, Adam, SGD, Adagrad\n",
    "import sys \n",
    "from keras.utils import CustomObjectScope\n",
    "\n",
    "#import numpy as np\n",
    "#sys.setrecursionlimit(2960)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-6\n",
    "eps = 1e-6\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def fbeta_score(y_true, y_pred, beta=1):\n",
    "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
    "        return 0\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "    return fbeta_score\n",
    "\n",
    "\n",
    "def cosine_distance(y1, y2):\n",
    "    mult =  tf.multiply(y1, y2)\n",
    "    cosine_numerator = tf.reduce_sum( mult, axis = -1)\n",
    "    y1_norm = tf.sqrt(tf.maximum(tf.reduce_sum(tf.square(y1), axis=-1 ), eps) ) \n",
    "    y2_norm = tf.sqrt(tf.maximum(tf.reduce_sum(tf.square(y2), axis=-1 ), eps) ) \n",
    "    return cosine_numerator / y1_norm / y2_norm\n",
    "\n",
    "def cal_relevancy_matrix(text_vector, hypo_vector):\n",
    "    text_vector_tmp = tf.expand_dims(text_vector, 1) # [batch_size, 1, question_len, dim]\n",
    "    hypo_vector_tmp = tf.expand_dims(hypo_vector, 2) # [batch_size, passage_len, 1, dim]\n",
    "    relevancy_matrix = cosine_distance(text_vector_tmp, hypo_vector_tmp) # [batch_size, passage_len, question_len]\n",
    "    return relevancy_matrix\n",
    "\n",
    "def mask_relevancy_matrix(relevancy_matrix, text_mask, hypo_mask):\n",
    "    relevancy_matrix = tf.multiply(relevancy_matrix, K.expand_dims(text_mask, 1))\n",
    "    relevancy_matrix = tf.multiply(relevancy_matrix, K.expand_dims(hypo_mask, 2))\n",
    "    return relevancy_matrix\n",
    "\n",
    "def max_mean_pooling(repres, cosine_matrix):\n",
    "    \n",
    "    repres.append(tf.reduce_max(cosine_matrix, axis = 2, keepdims  = True))\n",
    "    repres.append(tf.reduce_mean(cosine_matrix, axis = 2, keepdims  = True))\n",
    "\n",
    "    return repres\n",
    "\n",
    "def matching_layer(inputs):\n",
    "    forward_relevancy_matrix = cal_relevancy_matrix(inputs[0], inputs[2])\n",
    "    backward_relevancy_matrix = cal_relevancy_matrix(inputs[1], inputs[3])\n",
    "\n",
    "    representation = []\n",
    "\n",
    "    max_mean_pooling(representation, forward_relevancy_matrix)\n",
    "    max_mean_pooling(representation, backward_relevancy_matrix)\n",
    "    \n",
    "    return representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatchLayer(Layer):\n",
    "\n",
    "    def __init__(self, dim, seq_length, **kwargs):\n",
    "        super(MatchLayer, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.dim = dim\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        if not isinstance(input_shape, list):\n",
    "            raise ValueError('`MatchLayer` layer should be called '\n",
    "                             'on a list of inputs')\n",
    "        \n",
    "        if all([shape is None for shape in input_shape]):\n",
    "            return\n",
    "        \n",
    "        super(MatchLayer, self).build(input_shape)  # Be sure to call this somewhere!\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if not isinstance(inputs, list):\n",
    "            raise ValueError('A `MatchLayer` layer should be called ')\n",
    "        \n",
    "        return matching_layer(inputs)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if not isinstance(input_shape, list):\n",
    "            raise ValueError('A `MatchLayer` layer should be called '\n",
    "                             'on a list of inputs.')\n",
    "        \n",
    "        input_shapes = input_shape\n",
    "        output_shape = list(input_shapes[0])\n",
    "                             \n",
    "        return [ (None, output_shape[1] , 1) ] * 4 \n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'dim': self.dim,\n",
    "            'seq_length': self.seq_length\n",
    "        }\n",
    "        base_config = super(MatchLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "    \n",
    "    \n",
    "class MaxPoolingLayer(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MaxPoolingLayer, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        super(MaxPoolingLayer, self).build(input_shape)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return max_mean_pooling([], inputs)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):            \n",
    "        output_shape = list(input_shape)\n",
    "        return [ (None, output_shape[1] , 1) ] * 2\n",
    "    \n",
    "    def compute_mask(self, inputs, mask):\n",
    "        return [mask, mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.preprocessing.sequence import pad_sequences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_modelft  = 'D:\\models\\small-FTE-model.h5'\n",
    "path_modelwv = 'D:\\models\\small-FOL-model.h5'\n",
    "path_historyf='D:\\models\\small-FTE-history.npy'\n",
    "path_historyw='D:\\models\\small-FOL-history.npy'\n",
    "path_config = 'configl.pkl'\n",
    "configf = None\n",
    "graphf =None\n",
    "graphv=None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft():\n",
    "    global modelf, historyf,configf, graphf\n",
    "\n",
    "    \"\"\"load ML model and configuration\"\"\"\n",
    "    with CustomObjectScope({'tf':tf},{'K':K},{'MatchLayer': MatchLayer},{'MaxPoolingLayer':MaxPoolingLayer},{\"cal_relevancy_matrix\": cal_relevancy_matrix}):\n",
    "\n",
    "        modelf  = load_model(path_modelft)\n",
    "    historyf = np.load(path_historyf,allow_pickle=True).item()\n",
    "    graphf = tf.get_default_graph()\n",
    "    configf = pickle.load(open(path_config, 'rb'))\n",
    "    return(modelf, historyf,configf, graphf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wv():\n",
    "    global modelv,historyv, configv, graphv\n",
    "\n",
    "    \"\"\"load ML model and configuration\"\"\"\n",
    "    with CustomObjectScope({'tf':tf},{'K':K},{'MatchLayer': MatchLayer},{'MaxPoolingLayer':MaxPoolingLayer},{\"cal_relevancy_matrix\": cal_relevancy_matrix}):\n",
    "\n",
    "        \n",
    "        modelv  = load_model(path_modelwv)\n",
    "    historyv = np.load(path_historyw,allow_pickle=True).item()\n",
    "\n",
    "    graphv = tf.get_default_graph()\n",
    "    configv = pickle.load(open(path_config, 'rb'))\n",
    "    return(modelv, historyv,configv, graphv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
